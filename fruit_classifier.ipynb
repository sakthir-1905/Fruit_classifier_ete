{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92ad235a-72b5-4755-ac5d-8b69b90ecd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b29fa2-36b3-4887-b474-f9380aea376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to import training data\n",
    "data_path = r\"C:\\Users\\sakth\\OneDrive\\Desktop\\Course\\Deep Learning\\Topics\\Fruits Classification\\train\"\n",
    "# Number of types / categories\n",
    "num_types = 5 \n",
    "# Defining image size\n",
    "img_width, img_height = 150,150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8330b92-d78d-4c13-b1e7-8b819d63e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation \n",
    "# Training model with all possible types of data\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    validation_split = 0.2    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49046831-3929-4f7f-94b8-72befa354fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7760 images belonging to 5 classes.\n",
      "Found 1940 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "train_gen = data_gen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size = (img_width,img_height),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "validation_gen = data_gen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size = (img_width,img_height),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c6bef5-5b60-4cc7-9179-7af05f8c5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 3 convolution layer and 2 hidden layer\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "    Conv2D(32,kernel_size = (3,3), activation = \"relu\",input_shape = (img_width,img_height,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64,kernel_size = (3,3), activation = \"relu\"),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128,kernel_size = (3,3), activation = \"relu\"),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512,activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256,activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_types, activation = 'softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3838cba8-4b3c-48fb-a686-355472a16990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7cced0c-bf5d-419a-938f-2f1c8ec2dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 2s/step - accuracy: 0.4084 - loss: 1.3461 - val_accuracy: 0.4589 - val_loss: 1.2476\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/242\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 618ms/step - accuracy: 0.5312 - loss: 1.1338"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakth\\Anaconda\\anaconda_files\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 118ms/step - accuracy: 0.5312 - loss: 1.1338 - val_accuracy: 0.4646 - val_loss: 1.2484\n",
      "Epoch 3/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 895ms/step - accuracy: 0.5177 - loss: 1.1580 - val_accuracy: 0.4661 - val_loss: 1.2310\n",
      "Epoch 4/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 140ms/step - accuracy: 0.5000 - loss: 1.1326 - val_accuracy: 0.4719 - val_loss: 1.2085\n",
      "Epoch 5/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 863ms/step - accuracy: 0.5550 - loss: 1.0845 - val_accuracy: 0.4990 - val_loss: 1.1670\n",
      "Epoch 6/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 103ms/step - accuracy: 0.5312 - loss: 0.9955 - val_accuracy: 0.4995 - val_loss: 1.1762\n",
      "Epoch 7/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 918ms/step - accuracy: 0.5795 - loss: 1.0394 - val_accuracy: 0.5286 - val_loss: 1.1151\n",
      "Epoch 8/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 122ms/step - accuracy: 0.5000 - loss: 1.2677 - val_accuracy: 0.5255 - val_loss: 1.1119\n",
      "Epoch 9/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 951ms/step - accuracy: 0.6064 - loss: 0.9974 - val_accuracy: 0.5396 - val_loss: 1.1164\n",
      "Epoch 10/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 108ms/step - accuracy: 0.6562 - loss: 0.9725 - val_accuracy: 0.5417 - val_loss: 1.1310\n",
      "Epoch 11/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 909ms/step - accuracy: 0.6198 - loss: 0.9593 - val_accuracy: 0.5307 - val_loss: 1.1137\n",
      "Epoch 12/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 114ms/step - accuracy: 0.5312 - loss: 0.9917 - val_accuracy: 0.5234 - val_loss: 1.1302\n",
      "Epoch 13/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 878ms/step - accuracy: 0.6432 - loss: 0.9229 - val_accuracy: 0.5693 - val_loss: 1.0699\n",
      "Epoch 14/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.5000 - loss: 1.0876 - val_accuracy: 0.5589 - val_loss: 1.0661\n",
      "Epoch 15/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 877ms/step - accuracy: 0.6501 - loss: 0.9046 - val_accuracy: 0.5635 - val_loss: 1.0578\n",
      "Epoch 16/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.6250 - loss: 0.8262 - val_accuracy: 0.5682 - val_loss: 1.0564\n",
      "Epoch 17/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 859ms/step - accuracy: 0.6610 - loss: 0.8808 - val_accuracy: 0.5807 - val_loss: 1.0218\n",
      "Epoch 18/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 103ms/step - accuracy: 0.8125 - loss: 0.6178 - val_accuracy: 0.5849 - val_loss: 1.0184\n",
      "Epoch 19/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 894ms/step - accuracy: 0.6695 - loss: 0.8548 - val_accuracy: 0.6036 - val_loss: 1.0362\n",
      "Epoch 20/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 168ms/step - accuracy: 0.5938 - loss: 0.9398 - val_accuracy: 0.5943 - val_loss: 1.0372\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "output = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch = train_gen.samples // train_gen.batch_size,\n",
    "    epochs = 20,\n",
    "    validation_data = validation_gen,\n",
    "    validation_steps = validation_gen.samples // validation_gen.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f14bd5d2-e743-4782-b5b4-194678d9fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55fad8c2-8f4b-4f02-8051-d47c9d300f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 427ms/step - accuracy: 0.6093 - loss: 1.0230\n",
      "Accuracy : 60.93%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "loss, acc = model.evaluate(validation_gen)\n",
    "print(f\"Accuracy : {acc*100:.2f}%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad8307e9-dae5-496c-b605-faed3f7f4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with preprocessed data\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = r\"C:\\Users\\sakth\\OneDrive\\Desktop\\Course\\Deep Learning\\Topics\\Fruits Classification\\test\\Apple\\Apple (12).png\"\n",
    "img = image.load_img(img_path, target_size = (img_width,img_height))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis = 0)\n",
    "img_array = img_array / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ddf8666-f375-4732-aaab-265ee695932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step\n",
      "[[0.9029892  0.00180703 0.01843362 0.0119615  0.06480868]]\n",
      "Apple\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(img_array)\n",
    "print(pred)\n",
    "classes = ['Apple', 'Banana','Grape', 'Mango','Strawberry']\n",
    "index = np.argmax(pred)\n",
    "print(classes[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
